---
layout: post
title: "【Chapter 1】文系大学生が読み解くDeep Learning Book"
categories:
  - Deep Learning
tags:
  - Deep Learning, Machine Learning, AI
---

# 【Chapter 1】文系大学生が読み解くDeep Learning Book

## 概要

数学的素養がほとんど高校生止まりの
とある文系大学生が著名な[Deep Learning Book](http://www.deeplearningbook.org/)
を読み解いていきたいと思います。（＝翻訳・まとめ・解釈）

## きっかけ

今僕は丁度20歳なのですが、
とある偉大な先輩から
「僕が今2019年の20歳だったら間違いなくこの本を徹底的に読み込むね」
とおっしゃっていたので、
いざ奮起して頑張ります。

それでは早速いきたいと思います。

## Chapter 1

### 1.0 Introduction

- Deep Learningの大きな転換点の一つは、1997年に、IBM の Deep Blue が当時の世界チャンピオンを倒したこと。

- Machine Learning の例として、Logistic Regression や Naive Bayesなどが存在する。

- Machine Learning のデータの表現(representation)を特徴(feature) という。

- AutoEncoder(自己符号化器)によりデータの次元削減を行い、新たな特徴を獲得できる。

- MLP(Multilayer Perceptron・多層パーセプトロン)は結局はただのインプットからアウトプットを導く関数にしか過ぎない。

### 1.1 Who Should Read This Book? / 誰がこの本を読むべきか？

- 読者として想定しているのは、これからMachine Learning を専攻しようとしている大学生・大学院生、もしくは Deep Learning の技術を取れいれたいソフトウェア・エンジニア

- 本書のPart 1 は、基礎的な数学や Machine Learning のコンセプト中心

- 本書のPart 2 は、Deep Learning の近年の進歩について

- 本書のPart 3 は、これからの Deep Learning に不可欠な概念などについて

### 1.2 Historical Trends in Deep Learning / Deep Learning の過去のトレンドについて

- Deep Learning は、トレーニング の データの分量の拡大に伴い加速的に成長してきた。

- Deep Learning のモデル自体も、コンピュータの処理能力の飛躍に伴い、加速的に複雑になってきた。

- Deep Learning により、高度な複雑な問題においても精度高い予測をはじき出すことができるように。

### 1.2.1 The Many Names and Changing Fortunes of Neural Networks / Neural Networks の変遷について

- Deep Learning の歴史は 3つの区分(Cybernetics, Connectionism, Artificial Neural Networks)に分けることができる。

- 1950年代に開発されたADALINEは、初期のStochastic Gradient Descent(確率的勾配降下法)を用いていた。

- Linear Model(線形モデル)は、XOR関数を学習することができない。

- Neuroscience をベースに Deep Learning が発展してきた歴史がある。

- 現在の多くのNeural Networkでは、Neuron として、非線形関数のReLUを用いるように。

- University of Toronto の Geoffrey Hinton, University of Montreal の Yoshua Bengio, New York University の Yann LeCun より カナダの CIFAR による NCAPイニシアチブの遂行

### 1.2.2 Increasing Dataset Sizes / 肥大化傾向にあるデータセット容量

- デジタル化社会がデータセットの肥大化に大きく寄与

- Big Data 時代により大きなデータセットを用いて汎化性能が飛躍的に工場

- 小さいデータセットや教師なし学習への適用も研究分野としては重要になりつつある

### 1.2.3 Increasing Model Sizes / 肥大化傾向にあるモデルのサイズ

- 隠れ層が発明されてから、Neural Networkのモデルのサイズはおよそ2年半おきに倍増

- 1980・1990年代 の MNIST データセット、そして2000年代のCIFAR-10 データセット

- コンピューティング能力の加速的進化は、現代のDeep Learningの進化における大きな原動力

### 1.2.4 Increasing Accuracy, Complexity and Real-World Impact / 高まる精度・複雑度・現実社会へのインパクト

- 2012年度の ILSVRC に置いて、史上初めてエラーの度合いが26.1%から15.3%へと低下し、CNN(Convolutional Neural Networks / 畳み込み ニューラル ネットワーク)の台頭のきっかけに。

- Reinforcement Learning(強化学習)の発展

- 総じて、Deep Learning とは Machine Learning のアプローチの一つであり、高度な演算処理能力の発展により、加速度的に進化している。

## 最後に

間違いやご指摘などが御座いましたらご教示願います！

## 参考文献

https://deepage.net/deep_learning/2016/10/09/deeplearning_autoencoder.html
https://qiita.com/JunyaKaneko/items/b3ec906be4fb8cb713ad
http://blog.brainpad.co.jp/entry/2017/02/24/121500